---
date: 2020-03-16
title: Devlog 9 - Measuring Results and Impact
---
We have already discussed concepts of sharing authority in an earlier class (and in the reading by Seema Rao), and also the museum-visitor dynamic. What I got from the readings this week was that visitors’ experiences in museums are vast. What each person will get out of the museum experience is varied, and so from the museum’s perspective, building exhibits depends on the intentions of the museum. When Byrd-McDevitt talks about influences, I suspect we have not reached the imaginable limits of digital technology yet. With digital tools, including social media, but also things like online exhibits with audio (Mark Coffrey), a whole world of possibilities is opened up. 

When Eileen Hooper-Greenhill discusses the history of studying visitors, she essentially says that visitors are so diverse than quantitative data (mapping) is not sufficient for helping a museum determine what its exhibits should be. Ideally, museums need a mix of quantitative and qualitative data. Ultimately, a museum is trying to attract visitors and generate revenue (or at least demonstrate that it warrants existing). Both of these granular outcomes relate to the concept of demonstrating results, which Hooper-Greenhill talked about. 

In the wider government context, there is a lot of emphasis on demonstrating results to Canadians, showing that your program has had a visible impact. The issue is that impact for some programs, specifically social ones (i.e. relating to changing attitudes/behaviours) rather than changing something easily quantifiable such as economic outcomes (income, employment, etc.). For social programs, the main issue lies within what I said in a previous devlog, which is that the government struggles to recruit and retain specialists. This includes those that are experts at impact measurement. Complicated by the fact that there is often not a lot of impact, or knowhow on how to measure results or impact (which are different from outputs), that government uses basic metrics such as social media reach or dollars spent (which are outputs) and say that they are results, when compared year-over-year (they are still just outputs). 

With social programs, the solution is to combine your easily gathered outputs and associate them with narratives in the form of immediate, intermediate (and perhaps long-term) objectives. With these objectives, you can build a narrative that demonstrates, to a reasonable degree, results or impact. Nothing is perfect, but it is sometimes the best you can get with often tight deadlines, lack of direction, and often, lack of expertise. 

Lastly, the coronavirus has forced classes to go online, which is interesting to say the least. The datathons described by Milligan et al. sounded similar to the Heritage Jam, but that is not happening this year, unfortunately. I imagine it would have been pretty cool. I have also been advised by my director and manager to work from home for the foreseeable future. Unlike a lot of people, I tend to do better work (school and non-school work) when I am in a classroom or in an office setting. I will be at home seven days a week for a while, so I know I can get my work done, but what I already am finding difficult is to coordinate group work in an online-only space, especially something with no obvious endpoint. To summarize my feelings, they are pretty mixed. On one hand, I do not need to commute an hour to school/work and an hour and a half back home from school/work for a while. But, on the other hand, this is my last semester before I graduate (assuming I pass everything), so this kind of situation is pretty damn anticlimactic.
